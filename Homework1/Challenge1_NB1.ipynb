{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfolZq6vruX2"
      },
      "source": [
        "## Link to my drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDRQN4lYq5LQ",
        "outputId": "c94e7685-dcf7-434d-ab2a-514bbfa0bd75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/[2023-2024] AN2DL/Homework 1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2023-2024] AN2DL/Homework 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7ulDwfZr85B"
      },
      "source": [
        "## Libraries, warnings, etc.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-0FdbjnrfBp"
      },
      "outputs": [],
      "source": [
        "seed = 69\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlunVLCTrrn-",
        "outputId": "d58cd097-44e6-4a2b-e5ae-ad29be30accd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1Y8IHq1sKYk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXGnASgHk5YE"
      },
      "source": [
        "\n",
        "### Images Export and Import before and after cleaning (not needed once you have dataset_wo_duplicates.npz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8SD7USWR9fD"
      },
      "outputs": [],
      "source": [
        "#Save the images in drive\n",
        "num_images = 5200\n",
        "for i in range(num_images):\n",
        "  # Reorder the channels if necessary (for BGR to RGB conversion)\n",
        "  image = cv2.cvtColor(dataset['data'][i], cv2.COLOR_RGB2BGR)\n",
        "\n",
        "  #save imageXXXX.png\n",
        "  cv2.imwrite(\"./dataset/image\"+str(i).zfill(4)+\".png\",image)\n",
        "  #cv2.imwrite(\"./dataset2/image\"+str(i).zfill(4)+dataset['labels'][i]+\".png\",image)\n",
        "\n",
        "  #check savings\n",
        "  if i%100 == 0:\n",
        "    print(str(i).zfill(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPo2mUUXISsV"
      },
      "outputs": [],
      "source": [
        "from sys import breakpointhook\n",
        "# Specify the folder path where your images are located\n",
        "folder_path = './dataset_wo_duplicates'\n",
        "\n",
        "# Use os.listdir to get a list of all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Filter the list to include only image files (e.g., .jpg, .png, .jpeg, etc.)\n",
        "image_files = [file for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'))]\n",
        "\n",
        "# Data array of numpy file\n",
        "#data = np.ndarray(shape=(96,96,3),dtype='float32')\n",
        "image_list = []\n",
        "\n",
        "# Labels array of numpy file\n",
        "labels = np.empty(0, dtype=object)\n",
        "\n",
        "# Iterate through the list of image files and read each image using cv2\n",
        "for image_file in image_files:\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "    # Retrieve id\n",
        "    image_id =int(image_file[5:9])\n",
        "    #print(image_id)\n",
        "\n",
        "    # Use cv2.imread to read the image\n",
        "    image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "    #print(image)\n",
        "\n",
        "    # Add to Data and Labels\n",
        "    image_list.append(image)\n",
        "    #data = np.append(data,image,axis=0)\n",
        "    labels = np.append(labels,dataset['labels'][image_id])\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "data = np.array(image_list, dtype='float32')\n",
        "#print(data)\n",
        "np.savez('dataset_wo_duplicates.npz', data=data,labels=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxarSVSys9_o"
      },
      "source": [
        "## Loading dataset:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944TTWmptJLd"
      },
      "outputs": [],
      "source": [
        "# unzip = False\n",
        "\n",
        "# if unzip:\n",
        "#    !unzip public_data.zip\n",
        "\n",
        "dataset = np.load('dataset_wo_duplicates.npz', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwLPgvult7b6"
      },
      "outputs": [],
      "source": [
        "def load_images():\n",
        "  '''\n",
        "  Function to load rescaled and correctly sized pictures into a np.array\n",
        "  '''\n",
        "    images = []\n",
        "    for item in dataset['data']:\n",
        "        img = item\n",
        "        img = (img / 255).astype(np.float32)\n",
        "        img = tfkl.Resizing(96,96)(img)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPlThbck4Ssh"
      },
      "outputs": [],
      "source": [
        "# Loading images, labels and using one-hot encoding.\n",
        "X = load_images()\n",
        "y = dataset['labels']\n",
        "_ , y = np.unique(y, return_inverse=True)\n",
        "\n",
        "from collections import Counter\n",
        "counter = Counter(y)\n",
        "\n",
        "y = tfk.utils.to_categorical(y, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fUuUJPYe4KCz"
      },
      "outputs": [],
      "source": [
        "# Showing some of the images to check that everything works fine\n",
        "num_img = 15\n",
        "\n",
        "fig, axes = plt.subplots(3, num_img//3, figsize=(15, 9))\n",
        "for i in range(num_img):\n",
        "    ax = axes[i%3, i%num_img//3]\n",
        "    ax.imshow(np.clip(X[i], 0, 255))\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11pqpOFHDE8d"
      },
      "outputs": [],
      "source": [
        "# Splitting data\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=seed, test_size=.1, stratify=np.argmax(y,axis=1))\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size=len(X_test), stratify=np.argmax(y_train_val,axis=1))\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myAXiwZeJzTJ"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1]\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "patience = 25\n",
        "metadata = {}  # Dictionary for utility when plotting and compare how well (or not) models do\n",
        "\n",
        "# Early stopping implementation\n",
        "callbacks = [\n",
        "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True, mode='auto'),\n",
        "]\n",
        "\n",
        "print(f\"Input Shape: {input_shape}, Output Shape: {output_shape}, Batch Size: {batch_size}, Epochs: {epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9c6YcaHklWR"
      },
      "outputs": [],
      "source": [
        "def print_histories(metadata):\n",
        "  '''\n",
        "  Utility function that based on dictionary given as input, plots each model's history in terms of (val_)loss and (val_) accuracy\n",
        "  '''\n",
        "  plt.figure(figsize=(15,5))\n",
        "  for k in list(metadata.keys()):\n",
        "    plt.plot(metadata[k]['history']['loss'], alpha=.25, color=metadata[k]['color'][0], linestyle='--')\n",
        "    plt.plot(metadata[k]['history']['val_loss'], label=k, alpha=.9, color=metadata[k]['color'][0])\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title('Categorical Crossentropy')\n",
        "  plt.grid(alpha=.15)\n",
        "  plt.ylim([0,1])\n",
        "  plt.figure(figsize=(15,5))\n",
        "  for k in list(metadata.keys()):\n",
        "    be = metadata[k]['best_epoch']\n",
        "    bescore = metadata[k]['history']['val_accuracy'][be]\n",
        "    plt.plot(metadata[k]['history']['accuracy'], alpha=.25, color=metadata[k]['color'][1], linestyle='--')\n",
        "    plt.plot(metadata[k]['history']['val_accuracy'], label=k, alpha=.9, color=metadata[k]['color'][1])\n",
        "    plt.plot(be, bescore, marker='*', color=metadata[k]['color'][1], markersize=15)\n",
        "    plt.text(0.95*be, 1.02*bescore,\n",
        "             f'{bescore:.{3}g}', fontsize=12, color=metadata[k]['color'][1])\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title('Accuracy')\n",
        "  plt.grid(alpha=.15)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAeLRu0ekpqj"
      },
      "outputs": [],
      "source": [
        "def print_matrixandstats(preds, y_test):\n",
        "  '''\n",
        "  Utility function that plots confmatrix and statistics useful to check model performances\n",
        "  '''\n",
        "  confmat = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1))\n",
        "\n",
        "  accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1))\n",
        "  precision = precision_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1), average='macro')\n",
        "  recall = recall_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1), average='macro')\n",
        "  f1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1), average='macro')\n",
        "\n",
        "  print('Accuracy:', accuracy.round(4))\n",
        "  print('Precision:', precision.round(4))\n",
        "  print('Recall:', recall.round(4))\n",
        "  print('F1:', f1.round(4))\n",
        "\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  sns.heatmap(confmat.T, xticklabels=list(('Unhealthy','Healthy')), yticklabels=list(('Unhealthy','Healthy')), cmap='Greens', annot=True)\n",
        "  plt.xlabel('True labels')\n",
        "  plt.ylabel('Predicted labels')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ertHUzi9TOc9"
      },
      "source": [
        "## Adding some dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0EjYIMCTNFY"
      },
      "outputs": [],
      "source": [
        "def build_CNND(dropout_rate, input_shape=input_shape, output_shape=output_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    x = tfkl.Conv2D(filters=32, kernel_size=4, padding='same', name='conv0')(input_layer)\n",
        "    x = tfkl.ReLU(name='relu0')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=64, kernel_size=4, padding='same', name='conv1')(dropout)\n",
        "    x = tfkl.ReLU(name='relu1')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=128, kernel_size=4, padding='same', name='conv2')(dropout)\n",
        "    x = tfkl.ReLU(name='relu2')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=256, kernel_size=4, padding='same', name='conv3')(dropout)\n",
        "    x = tfkl.ReLU(name='relu3')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp3')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=512, kernel_size=4, padding='same', name='conv4')(dropout)\n",
        "    x = tfkl.ReLU(name='relu4')(x)\n",
        "\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=output_shape, activation='softmax',name='Output')(dropout)\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNND')\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TIdtT-DThSN"
      },
      "outputs": [],
      "source": [
        "# If more, doesn't learn a thing\n",
        "dropout_rate = 1/8\n",
        "\n",
        "CNND_model = build_CNND(dropout_rate, input_shape)\n",
        "CNND_model.summary()\n",
        "tfk.utils.plot_model(CNND_model, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQMNBVdMT6sp"
      },
      "outputs": [],
      "source": [
        "history = CNND_model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pxh0XNXCc7O"
      },
      "outputs": [],
      "source": [
        "# Metadata: made by the model and its history, chooses a color to be displayed and holds best epoch (just in case Early Stopping isn't used)\n",
        "metadata['CNN w Dropout'] = {\n",
        "    'model': CNND_model,\n",
        "    'history': history,\n",
        "    'color': ('#f52f07', '#f52f07'),\n",
        "    'best_epoch': np.argmax(history['val_accuracy'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXn0FTZBRzYS"
      },
      "outputs": [],
      "source": [
        "CNND_model.save('CNN w Dropout')\n",
        "\n",
        "del CNND_model\n",
        "\n",
        "CNND_model = tfk.models.load_model('CNN w Dropout')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rKpP-DnW5zF"
      },
      "outputs": [],
      "source": [
        "preds = CNND_model.predict(X_test, verbose=0)\n",
        "\n",
        "print(\"Predictions Shape:\", preds.shape)\n",
        "\n",
        "print_matrixandstats(preds, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z3F2TTE86n_"
      },
      "source": [
        "## Small modifies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybXSOFrf8_at"
      },
      "outputs": [],
      "source": [
        "# Modifying learning rate, kernel_size, adding an intermediate Dense\n",
        "def build_CNNDv2(dropout_rate, input_shape=input_shape, output_shape=output_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv0')(input_layer)\n",
        "    x = tfkl.ReLU(name='relu0')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='conv1')(dropout)\n",
        "    x = tfkl.ReLU(name='relu1')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=128, kernel_size=3, padding='same', name='conv2')(dropout)\n",
        "    x = tfkl.ReLU(name='relu2')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=256, kernel_size=3, padding='same', name='conv3')(dropout)\n",
        "    x = tfkl.ReLU(name='relu3')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp3')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=512, kernel_size=3, padding='same', name='conv4')(dropout)\n",
        "    x = tfkl.ReLU(name='relu4')(x)\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Dense(units=256, activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=output_shape, activation='softmax',name='Output')(dropout)\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNNDv2')\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae4W5hU-_dxY"
      },
      "outputs": [],
      "source": [
        "CNNDv2_model = build_CNNDv2(dropout_rate, input_shape)\n",
        "CNNDv2_model.summary()\n",
        "tfk.utils.plot_model(CNNDv2_model, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJrrmD7G_mub"
      },
      "outputs": [],
      "source": [
        "history = CNNDv2_model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G12tF2KV_rLA"
      },
      "outputs": [],
      "source": [
        "metadata['CNN w Dropout v2'] = {\n",
        "    'model': CNNDv2_model,\n",
        "    'history': history,\n",
        "    'color': ('#0990de', '#0990de'),\n",
        "    'best_epoch': np.argmax(history['val_accuracy'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obpfEK_MCyHB"
      },
      "outputs": [],
      "source": [
        "CNNDv2_model.save('CNN w Dropout v2')\n",
        "\n",
        "del CNNDv2_model\n",
        "\n",
        "CNNDv2_model = tfk.models.load_model('CNN w Dropout v2')\n",
        "\n",
        "preds = CNNDv2_model.predict(X_test, verbose=0)\n",
        "\n",
        "print(\"Predictions Shape:\", preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fAT6-QFEfrP"
      },
      "outputs": [],
      "source": [
        "confmat = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1))\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1))\n",
        "precision = precision_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(preds, axis=-1), average='macro')\n",
        "\n",
        "print('Accuracy:', accuracy.round(4))\n",
        "print('Precision:', precision.round(4))\n",
        "print('Recall:', recall.round(4))\n",
        "print('F1:', f1.round(4))\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confmat.T, xticklabels=list(('Unhealthy','Healthy')), yticklabels=list(('Unhealthy','Healthy')), cmap='Greens', annot=True)\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzVudNN7M8-F"
      },
      "source": [
        "## Adding regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTBNseu3Mxm0"
      },
      "outputs": [],
      "source": [
        "def build_CNNDv3(dropout_rate, input_shape=input_shape, output_shape=output_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "    l_lambda = 0.0075\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv0')(input_layer)\n",
        "    x = tfkl.ReLU(name='relu0')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='conv1')(dropout)\n",
        "    x = tfkl.ReLU(name='relu1')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=128, kernel_size=3, padding='same', name='conv2')(dropout)\n",
        "    x = tfkl.ReLU(name='relu2')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=256, kernel_size=3, padding='same', name='conv3')(dropout)\n",
        "    x = tfkl.ReLU(name='relu3')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp3')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=512, kernel_size=3, padding='same', name='conv4')(dropout)\n",
        "    x = tfkl.ReLU(name='relu4')(x)\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l_lambda))(dropout)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=output_shape, activation='softmax',name='Output', kernel_regularizer=tf.keras.regularizers.L1L2(l_lambda))(dropout)\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNNDv3')\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90j5WE93Mxm2"
      },
      "outputs": [],
      "source": [
        "CNNDv3_model = build_CNNDv3(dropout_rate, input_shape)\n",
        "CNNDv3_model.summary()\n",
        "tfk.utils.plot_model(CNNDv3_model, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUFUfjg9Mxm3"
      },
      "outputs": [],
      "source": [
        "history = CNNDv3_model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsMpROs6Mxm5"
      },
      "outputs": [],
      "source": [
        "metadata['CNN w Dropout v3'] = {\n",
        "    'model': CNNDv3_model,\n",
        "    'history': history,\n",
        "    'color': ('#7f0bde', '#7f0bde'),\n",
        "    'best_epoch': np.argmax(history['val_accuracy'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1UcdMYGMxm6"
      },
      "outputs": [],
      "source": [
        "CNNDv3_model.save('CNN w Dropout v3')\n",
        "\n",
        "del CNNDv3_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r4maEYt1Dg4"
      },
      "outputs": [],
      "source": [
        "CNNDv3_model = tfk.models.load_model('CNN w Dropout v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQRsZErDEWHp"
      },
      "outputs": [],
      "source": [
        "preds = CNNDv3_model.predict(X_test, verbose=0)\n",
        "print(\"Predictions Shape:\", preds.shape)\n",
        "\n",
        "print_matrixandstats(preds, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-ntT9S2Z_GL"
      },
      "source": [
        "## Adding some augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSTyMw-yaI7c"
      },
      "outputs": [],
      "source": [
        "def build_CNNDA(dropout_rate, input_shape=input_shape, output_shape=output_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "    l_lambda = 0.0005\n",
        "\n",
        "    preprocessing = tf.keras.Sequential([tfkl.RandomRotation(0.3),\n",
        "                                         tfkl.RandomTranslation(0.25,0.25),\n",
        "                                         tfkl.RandomFlip(\"horizontal\")], name='preprocessing')\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "    preprocessing = preprocessing(input_layer)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv0')(preprocessing)\n",
        "    x = tfkl.ReLU(name='relu0')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='conv1')(dropout)\n",
        "    x = tfkl.ReLU(name='relu1')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=128, kernel_size=3, padding='same', name='conv2')(dropout)\n",
        "    x = tfkl.ReLU(name='relu2')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=256, kernel_size=3, padding='same', name='conv3')(dropout)\n",
        "    x = tfkl.ReLU(name='relu3')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp3')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=512, kernel_size=3, padding='same', name='conv4')(dropout)\n",
        "    x = tfkl.ReLU(name='relu4')(x)\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l_lambda))(dropout)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=output_shape, activation='softmax',name='Output', kernel_regularizer=tf.keras.regularizers.L1L2(l_lambda))(dropout)\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNNDA')\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIfJH6y4gYWC"
      },
      "outputs": [],
      "source": [
        "CNNDA_model = build_CNNDA(dropout_rate, input_shape)\n",
        "CNNDA_model.summary()\n",
        "tfk.utils.plot_model(CNNDA_model, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SxmAF_Ugaej"
      },
      "outputs": [],
      "source": [
        "history = CNNDA_model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uey2A1oscxJv"
      },
      "outputs": [],
      "source": [
        "metadata['CNND Augmentation'] = {\n",
        "    'model': CNNDA_model,\n",
        "    'history': history,\n",
        "    'color': ('#0bd98a', '#0bd98a'),\n",
        "    'best_epoch': np.argmax(history['val_accuracy'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc9WabfPcxJw"
      },
      "outputs": [],
      "source": [
        "CNNDA_model.save('CNND Augmentation')\n",
        "#CNNDA_model.save('CNND Augmentationx3')\n",
        "\n",
        "del CNNDA_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DTFS8vacxJw"
      },
      "outputs": [],
      "source": [
        "CNNDA_model = tfk.models.load_model('CNND Augmentation')\n",
        "#CNNDA_model = tfk.models.load_model('CNND Augmentationx3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsUucy0wcxJx"
      },
      "outputs": [],
      "source": [
        "preds = CNNDA_model.predict(X_test, verbose=0)\n",
        "print(\"Predictions Shape:\", preds.shape)\n",
        "\n",
        "print_matrixandstats(preds, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAAjlKXPLeI"
      },
      "source": [
        "## Basic Model with added augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIWu3z0lPZ5e"
      },
      "outputs": [],
      "source": [
        "# Taking back the kernel size to 4\n",
        "def build_CNND_BaseA(dropout_rate, input_shape=input_shape, output_shape=output_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    preprocessing = tf.keras.Sequential([tfkl.RandomRotation(0.3),\n",
        "                                         tfkl.RandomTranslation(0.25,0.25),\n",
        "                                         tfkl.RandomFlip(\"horizontal\")], name='preprocessing')\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "    preprocessing = preprocessing(input_layer)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=32, kernel_size=4, padding='same', name='conv0')(preprocessing)\n",
        "    x = tfkl.ReLU(name='relu0')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=64, kernel_size=4, padding='same', name='conv1')(dropout)\n",
        "    x = tfkl.ReLU(name='relu1')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=128, kernel_size=4, padding='same', name='conv2')(dropout)\n",
        "    x = tfkl.ReLU(name='relu2')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=256, kernel_size=4, padding='same', name='conv3')(dropout)\n",
        "    x = tfkl.ReLU(name='relu3')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp3')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=512, kernel_size=4, padding='same', name='conv4')(dropout)\n",
        "    x = tfkl.ReLU(name='relu4')(x)\n",
        "\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    dropout = tfkl.Dropout(dropout_rate, seed=seed)(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=output_shape, activation='softmax',name='Output')(dropout)\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNND_BaseA')\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmdjO8BMPZ6C"
      },
      "outputs": [],
      "source": [
        "CNND_BaseAmodel = build_CNND_BaseA(dropout_rate, input_shape)\n",
        "CNND_BaseAmodel.summary()\n",
        "tfk.utils.plot_model(CNND_BaseAmodel, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbA7z8EoPZ6G"
      },
      "outputs": [],
      "source": [
        "history = CNND_BaseAmodel.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vufaaR7tPZ6I"
      },
      "outputs": [],
      "source": [
        "metadata['CNN w Dropout Base+A'] = {\n",
        "    'model': CNND_BaseAmodel,\n",
        "    'history': history,\n",
        "    'color': ('#db18d8', '#db18d8'),\n",
        "    'best_epoch': np.argmax(history['val_accuracy'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw4icXyqPZ6J"
      },
      "outputs": [],
      "source": [
        "CNND_BaseAmodel.save('CNN w Dropout Base+A')\n",
        "\n",
        "del CNND_BaseAmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF3d1whZPZ6K"
      },
      "outputs": [],
      "source": [
        "CNND_BaseAmodel = tfk.models.load_model('CNN w Dropout Base+A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djhb99_gPZ6L"
      },
      "outputs": [],
      "source": [
        "preds = CNND_BaseAmodel.predict(X_test, verbose=0)\n",
        "\n",
        "print(\"Predictions Shape:\", preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3mEILu8PZ6M"
      },
      "outputs": [],
      "source": [
        "print_matrixandstats(preds, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWcZ1bDTMcBV"
      },
      "source": [
        "## Models comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoIuXXJv_rxL"
      },
      "outputs": [],
      "source": [
        "print_histories(metadata)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nfolZq6vruX2",
        "sXGnASgHk5YE",
        "bzVudNN7M8-F"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}